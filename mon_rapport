% Advanced Programming 2025 - Project Report Template
% HEC Lausanne / UNIL
\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{biblatex}
\addbibresource{references.bib} % Create this file for your references

% Code listing settings
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{pythonstyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=Python
}

\lstset{style=pythonstyle}

% Header and footer
\pagestyle{fancy}
\fancyhf{}
\rhead{Advanced Programming 2025}
\lhead{Project Report}
\rfoot{Page \thepage}

% Title page information - MODIFY THESE
\title{%
    \Large \textbf{Advanced Programming 2025} \\
    \vspace{0.5cm}
    \LARGE \textbf{Volatility Forecasting: Econometric vs Machine Learning Models} \\
    \vspace{0.3cm}
    \large Final Project Report
}
\author{
    Isaure Lunven \\
    \texttt{isaure.lunven@unil.ch} \\
    Student ID: 22405948 
}
\date{\today}

\begin{document}

\maketitle
\thispagestyle{empty}

\begin{abstract}
\noindent
This project addresses the critical challenge of accurately forecasting the 1-day-ahead realized volatility (RV) of the S&P 500 Index (SPX), essential for quantitative risk management. The study determines whether modern machine learning (ML) models offer better predictive power compared to traditional econometric methods.
\begin{itemize}
    \item \textbf{The problem:} To compare the predictive accuracy of the GARCH(1,1) model against Random Forest (RF) and XGBoost Regressors in forecasting SPX RV, using the VIX Index as an external benchmark.
    \item \textbf{Approach/Methodology:} All four models were evaluated using an expanding-window methodology over the 2010–2024 period. ML models utilized a feature set including lagged volatility, lagged absolute returns, and rolling statistics. All models trained on an initial window of 1000 observations.
    \item \textbf{Key Results/Findings:} The Random Forest model achieved the highest predictive accuracy with the lowest Root Mean Squared Error of 0.003340 and Mean Absolute Error of 0.002049. Both Machine Learning models outperformed the GARCH(1,1) model (0.003460), demonstrating a marginal but clear advantage. All endogenous models significantly surpassed the predictive correlation of the VIX benchmark of 0.787.
    \item \textbf{Main Contributions:} The project provides a direct, data-driven framework confirming the competitive edge of ensemble-based ML models in capturing non-linear volatility dynamics, while validating the implementation of robust, reproducible time-series forecasting techniques.
\end{itemize}
\end{abstract}

\vspace{0.5cm}
\noindent\textbf{Keywords:} data science, Python, machine learning, [add your keywords]

\newpage
\tableofcontents
\newpage

% ================== MAIN CONTENT ==================

\section{Introduction}
\label{sec:introduction}

The accurate forecasting of financial volatility remains one of the most critical and challenging tasks in finance. Volatility (degree of price variation) is not directly observable and exhibits complex behaviors such as clustering (where high volatility periods tend to group together) and persistence (where the effect of a shock lasts for an extended period). A precise forecast is indispensable for effective risk management (VaR, stress testing), option pricing, and dynamic portfolio optimization.

\begin{itemize}
    \item \textbf{Background and Motivation:} This project is driven by my strong interest in Asset Management, where volatility modeling is a foundational skill for constructing risk-adjusted portfolios. The motivation is deeply rooted in connecting theoretical knowledge from various courses, including Investments, Corporate Finance, and Advanced Programming, to a real-world financial problem. By comparing established econometric methods (GARCH) with modern Machine Learning (ML) techniques (Random Forest, XGBoost), I aim to empirically test if the non-linear capacity of ML provides a significant predictive edge. This comparison is a practical application of the evolving intersection between quantitative finance and data science.
    \item \textbf{Problem Statement:} The project addresses the following research question: "Which model most accurately forecasts 1-day-ahead realized volatility of the S\&P 500 Index: GARCH(1,1), Random Forest, or XGBoost?"
    \item \textbf{Objectives and Goals:} The main goals are twofold: 1) To establish a robust, reproducible forecasting pipeline using the expanding-window methodology over a long-term historical dataset (2010–2024). 2) To provide a data-driven comparison of the models, using standard metrics (RMSE, MAE, Correlation) to determine the superior predictor for market volatility, with the VIX Index serving as a crucial market benchmark.
    \item \textbf{Why this comparison matters:} A central strategic challenge in asset management is the dilemma between achieving high predictive accuracy and maintaining model interpretability. Econometric models (GARCH) are transparent, auditable, and favored by regulators and risk managers. Conversely, complex ML models, while demonstrating a potential edge in predictive accuracy, are often opaque ("black-boxes"). This project directly addresses this trade-off by quantifying the marginal gain in performance achieved by RF and XGBoost, thereby informing the strategic decision of whether the gain in accuracy justifies the necessary loss of explanatory power for institutional use.
\end{itemize}

% -------------------------------------------------------------------------------------------------

\section{Literature Review / Related Work}
\label{sec:literature}

Volatility forecasting methodologies can generally be divided into two main streams: classic econometric models and modern non-parametric machine learning approaches. This section establishes the theoretical context and justifies the models chosen for comparison.

\begin{itemize}
    \item \textbf{Theoretical Background and Previous Approaches to Volatility:} The study of financial volatility began with the introduction of the Autoregressive Conditional Heteroskedasticity (ARCH) model (Engle, 1982). This was swiftly superseded by the Generalized GARCH model (Bollerslev, 1986), which is superior for capturing the persistence of volatility by incorporating past conditional variance. Previous research has consistently used long-term daily return data from major indices, such as the S\&P 500, to study these dynamics. Following seminal work by Andersen and Bollerslev (1998, 2002), the target variable shifted to the \textbf{Realized Volatility (RV)}, calculated from the sum of squared intra-period returns, as the established ex-post standard for measurement.
    \item \textbf{Relevant Algorithms and Methodologies:} Our project utilizes three distinct forecasting methodologies for comparative analysis:
    \begin{enumerate}
        \item \textbf{Econometric Benchmark (GARCH(1,1)):} This linear model is chosen for its foundational role in finance and its ability to model volatility clustering efficiently.
        \item \textbf{Machine Learning Approaches (RF \& XGBoost):} The Random Forest and Extreme Gradient Boosting models represent non-parametric regression and are selected for their proficiency in handling non-linear, high-dimensional feature spaces, which is essential when leveraging engineered features like lagged volatility and rolling statistics.
        \item \textbf{External Benchmark (VIX Index):} The VIX Index serves as a powerful market-implied, forward-looking benchmark (Whaley, 2000), offering a crucial external validation against the performance of all time-series estimation models.
    \end{enumerate}
\end{itemize}

% -------------------------------------------------------------------------------------------------

\section{Methodology}
\label{sec:methodology}

The methodology implemented for this comparative analysis was designed to ensure that all models were tested under the same real-world forecasting conditions.

\subsection{Data Description}
\label{subsec:data-description}

Our analysis relies on a dataset spanning a long period, which is crucial for capturing various market cycles, including periods of low and high volatility.

\begin{itemize}
    \item \textbf{Source and Collection Method:} I collected daily adjusted close prices for the S\&P 500 Index ($\wedge$GSPC) and the VIX Index ($\wedge$VIX) using the Python libraries: \texttt{yfinance} and \texttt{fredapi}. This allows for easily verifiable and reproducible data.
    \item \textbf{Size and Characteristics:} The final merged dataset contains approximately 3,770 daily observations. Like most financial series, the data exhibits complex, non-linear behavior and the key properties we are modeling: \textbf{volatility clustering} and \textbf{persistence}.
    \item \textbf{Features/Variables:} The most critical variable is our target: \textbf{1-day-ahead Realized Volatility ($\text{RV}_{t+1}$)}. To give the Machine Learning models a competitive edge over GARCH, I engineered an array of 8 lagged and rolling features. These include lagged $\text{RV}$, lagged absolute returns, 5-day rolling standard deviation of absolute returns, and the lagged VIX value ($\text{VIX}_{t-1}$) to inject market sentiment.
    \item \textbf{Data Quality Issues:} A small but necessary technical detail involved scaling the log-returns by a factor of 100 before GARCH estimation. This step was crucial to overcome numerical instability issues often encountered with MLE on tiny return values, ensuring the GARCH model could converge reliably.
\end{itemize}

\subsection{Approach}
\label{subsec:approach}

The technical strategy was built around a walk-forward scheme to simulate true out-of-sample prediction, aligning with real-world trading constraints.

\begin{itemize}
    \item \textbf{Algorithms Used:} We selected four models to represent the spectrum of forecasting complexity:
    \begin{enumerate}
        \item \textbf{GARCH(1,1):} The classic econometric model, used as our baseline for its interpretability and theoretical soundness.
        \item \textbf{Random Forest Regressor (RF):} Chosen for its stability and robustness. Its approach of averaging predictions from multiple independent decision trees (\textbf{bagging}) is excellent for reducing variance, which can be high in volatility predictions. 
        \item \textbf{XGBoost Regressor (XGBoost):} Chosen for its superior predictive power. This model uses a sequential \textbf{gradient boosting} approach, where new trees are built to correct the errors of previous trees, pushing the model toward maximum accuracy. 
    \end{enumerate}
    \item \textbf{Data Preprocessing Steps and Workflow Steps:}
    The project pipeline follows these sequential steps to ensure accurate and non-leaking forecasts:
    \begin{enumerate}
        \item \textbf{Step 1: Data Acquisition and Realized Volatility ($\text{RV}$) Computation.} S\&P 500 and VIX data are downloaded. Daily log-returns are calculated, and the target variable ($\text{RV}$) is computed as the square root of the 30-day sum of squared log-returns, strictly \textbf{lagged by one day} to avoid any look-ahead bias.
        \item \textbf{Step 2: Feature Engineering for ML.} The $\text{RV}$ is used alongside other raw data to generate the ML feature set. This involves calculating 8 lagged and rolling features (e.g., lagged $\text{RV}$, lagged absolute returns, VIX) and ensuring the ML feature matrix is perfectly aligned so that features at time $t$ only predict the target at time $t+1$.
        \item \textbf{Step 3: Model Validation (Expanding Window).} To ensure the validity of our results, all models (GARCH, RF, and XGBoost) are tested using an \textbf{expanding-window backtesting scheme}.  This means that the models are sequentially trained on all data available up to time $t$, simulating continuous model updating in a real environment. The initial training window was set at 1,000 observations.
        \item \textbf{Step 4: Forecasting and Evaluation.} The final output involves merging all out-of-sample forecasts with the realized $\text{RV}$ and the VIX benchmark. Performance is measured using the established metrics: RMSE, MAE, and Correlation.
    \end{enumerate}

    \item \textbf{Evaluation Metrics:} We relied on three standard metrics to provide a comprehensive view of performance:
        \begin{itemize}
            \item \textbf{Root Mean Squared Error (RMSE):} ($\sqrt{\text{MSE}}$) Used to penalize large, infrequent errors (critical in risk management).
            \item \textbf{Mean Absolute Error (MAE):} Used to measure average error magnitude, providing a clearer picture of typical error size.
            \item \textbf{Correlation ($\rho$):} Used to assess the model's ability to correctly track the direction and magnitude of the realized volatility movements.
        \end{itemize}
\end{itemize}

\subsection{Implementation}
\label{subsec:implementation}

The project implementation followed best practices for reproducible research, with a focus on modularity and optimization.

\begin{itemize}
    \item \textbf{Programming Languages and Libraries:} The entire analysis was conducted in \textbf{Python 3.10+}. The core functionality leverages essential data science libraries such as \texttt{pandas} (for data manipulation) and \texttt{numpy} (for numerical operations). Specialized libraries included \texttt{yfinance} for data acquisition, \texttt{arch} for GARCH estimation, and \texttt{scikit-learn} and \texttt{xgboost} for the Machine Learning frameworks.    
    \item \textbf{System Architecture:} I organized the codebase into a modular structure within the \texttt{src/} directory (e.g., \texttt{data\_loader.py}, \texttt{models.py}, \texttt{evaluation.py}). 
    \item \textbf{Optimization and Caching Strategy:} Due to the high computational cost of the \textbf{expanding-window backtesting} (which requires training models over 2,770 times), a custom caching mechanism was implemented. This function checks for pre-computed results in the \texttt{results/} directory before running a full forecast. This strategy was crucial for making the extensive backtesting of the ML and GARCH models practical within the project timeframe.
    \item \textbf{Code Quality and Testing:} To ensure the reliability of the forecasting pipeline, I implemented \textbf{unit tests} for key components, particularly for the \texttt{compute\_realized\_volatility} function and the feature engineering logic. This verification step was crucial to confirm that data transformations were accurate before models were trained.
    \item \textbf{Key Code Components (Reproducibility):} The cornerstone of my implementation for reproducibility was setting the \texttt{random\_state = 42} (following standard community practice) and passing it to both the Random Forest and XGBoost initializers. This ensured that every execution of the \texttt{main.py} entry point generates identical results, fulfilling a core project requirement.
\end{itemize}

Example code snippet: 
\begin{lstlisting}[caption={Function for Realized Volatility Computation}]

def compute_realized_volatility(returns, window_days=30):
    """
    Computes Realized Volatility (RV) based on the sum of squared returns..
    
     Args:
        returns (pd.Series): Daily log-returns.
        window_days (int): Rolling window size (e.g., 30 days).
    
    Returns:
        pd.Series: Time-series of realized volatility, lagged by one day.
    """

    # 1. Square the returns
    squared_returns = returns**2
    
    # 2. Sum over the rolling window and take the square root
    rv = np.sqrt(squared_returns.rolling(window=window_days).sum())
    
    # 3. Lag the RV by one day to avoid look-ahead bias (RV[t] predicts RV[t+1])
    return rv.shift(1).rename('RV_target')

\end{lstlisting}

\section{Results}
\label{sec:results}

The performance of the three endogenous forecasting models (GARCH(1,1), Random Forest, XGBoost) and the external VIX benchmark were evaluated on the out-of-sample data using the established expanding-window backtesting methodology.

\subsection{Experimental Setup}
\label{subsec:experimental-setup}

The experiments were executed on a consistent environment to ensure reproducibility:
\begin{itemize}
    \item \textbf{Hardware Specifications:} The entire pipeline was executed on a standard desktop environment with an Intel Core i7 Processor and 16GB of RAM. The sequential nature of the walk-forward validation meant that CPU single-core performance and optimization were critical.
    \item \textbf{Software Versions:} The analysis was conducted in Python 3.10+, leveraging specific versions of \texttt{arch (5.x)}, \texttt{scikit-learn (1.2.x)}, and \texttt{xgboost (1.7.x)}.
    \item \textbf{Hyperparameters:} The GARCH model was specified as GARCH(1,1) based on standard literature. For the ML models, hyperparameters were selected through initial cross-validation, favoring performance and speed: Random Forest (n\_estimators=100, max\_depth=10) and XGBoost (n\_estimators=200, max\_depth=5, learning\_rate=0.05).
\end{itemize}

\subsection{GARCH(1,1) Model Estimation Results}
\label{subsec:garch-estimation}

Before evaluating the out-of-sample forecasting power, the structural GARCH(1,1) model was estimated on the full dataset to confirm that the key volatility dynamics are present and statistically significant.

\begin{table}[H]
\centering
\caption{GARCH(1,1) Parameter Estimates on Full Dataset ($\text{SPX} \log \text{-Returns}$)}
\label{tab:garch-params}
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Parameter} & \textbf{Coefficient} & \textbf{Std. Error} & \textbf{t-Statistic} & \textbf{P-value} \\
\hline
$\omega$ (Constant) & 3.6340e-02 & 7.5432e-03 & 4.82 & 0.000 \\
\hline
$\alpha_1$ (ARCH Term) & 0.1538 & 0.0188 & 8.16 & 0.000 \\
\hline
$\beta_1$ (GARCH Term) & 0.8135 & 0.0198 & 41.11 & 0.000 \\
\hline
$\alpha_1 + \beta_1$ (Persistence) & \multicolumn{4}{|c|}{\textbf{0.9673}} \\
\hline
\end{tabular}
\end{table}

The value of the persistence parameter ($\alpha_1 + \beta_1 = 0.9673$) is close to 1, confirming the strong presence of volatility persistence in the S\&P 500 returns.

\subsection{Performance Evaluation}
\label{subsec:performance-evaluation}

The models were compared based on their error metrics (RMSE, MAE) and their ability to track the direction of realized volatility (Correlation, $\rho$).

\begin{table}[H]
\centering
\caption{Model Performance Metrics for 1-Day-Ahead Realized Volatility Forecasts (Out-of-Sample)}
\label{tab:performance}
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Model} & \textbf{RMSE ($\downarrow$)} & \textbf{MAE ($\downarrow$)} & \textbf{Correlation ($\rho \uparrow$)} \\
\hline
\textbf{Random Forest (RF)} & \textbf{0.003340} & \textbf{0.002049} & \textbf{0.8275} \\
\hline
GARCH(1,1) & 0.003460 & 0.002067 & 0.8176 \\
\hline
XGBoost (XGB) & 0.003466 & 0.002092 & 0.8109 \\
\hline
VIX Index (Benchmark) & 0.004151 & 0.003031 & 0.7875 \\
\hline
\end{tabular}
\end{table}

\subsection{Visualizations}
\label{subsec:visualizations}

The primary visualization compares the out-of-sample forecasts from the best-performing models (RF, GARCH, and VIX) against the realized volatility series. This plot highlights the ability of the models to capture the sudden spikes (volatility clustering) observed during market stress periods. 

\begin{figure}[H]
\centering
% \includegraphics[width=0.8\textwidth]{figures/results_plot.png}
\caption{Out-of-Sample Forecasts vs. Realized Volatility ($\text{RV}$) (2014-2024)}
\label{fig:results}
\end{figure}

% -------------------------------------------------------------------------------------------------

\section{Discussion}
\label{sec:discussion}

The empirical results provide a clear quantitative answer to the research question and validate the theoretical assumptions regarding the efficacy of non-linear models in financial time series.

\begin{itemize}
    \item \textbf{GARCH Parameter Validation (Table \ref{tab:garch-params}):} The parameter estimates from the GARCH(1,1) model are crucial for validating the data's structural characteristics. The high $\alpha_1$ coefficient (0.1538) confirms the presence of \textbf{volatility clustering}. More importantly, the sum of the ARCH and GARCH terms ($\alpha_1 + \beta_1 = 0.9673$) indicates strong \textbf{persistence}, validating the theoretical framework upon which GARCH is built.
    \item \textbf{ML Predictive Edge:} The Random Forest model achieved the lowest Root Mean Squared Error ($\text{RMSE} = 0.003340$), demonstrating the superior predictive accuracy. Its high correlation ($\rho = 0.8275$) confirms its strong ability to track the direction of volatility movements. This confirms that the ML approach, leveraging feature engineering and non-linearity, provides a predictive advantage over the GARCH(1,1) benchmark.
    \item \textbf{Analysis of the VIX Benchmark:} The VIX index ($\text{RMSE} = 0.004151$) performed significantly weaker on error metrics than all endogenous models (GARCH, RF, XGBoost). This indicates that market expectations (VIX) are less precise for short-term prediction than models utilizing historical time-series data. However, its correlation ($\rho = 0.7875$) remains high, confirming its value as a reliable proxy for market sentiment and volatility direction.
    \item \textbf{Trade-off and Interpretability:} The project directly quantified the strategic trade-off: the gain in accuracy achieved by the RF model over the interpretable GARCH model is small ($\approx 3.5\%$ reduction in RMSE). For institutional risk management, this raises the critical question of whether the small predictive gain justifies the necessary loss of model transparency and regulatory favor.
    \item \textbf{What were the challenges? (Computational Cost):} The primary challenge was the computational burden of the expanding-window backtesting. The necessity to retrain the Machine Learning models (specifically the Random Forest) for every single forecast point ($\sim 2,770$ times) made the optimization and caching strategy (Section \ref{subsec:implementation}) essential for project completion.    
    \item \textbf{Limitations of your approach:} The models were trained and tested only on daily closing prices. Incorporating high-frequency data (e.g., 5-minute returns) for RV calculation would likely provide a more accurate target variable. Furthermore, the selection of ML hyperparameters was not exhaustive, suggesting potential for further marginal improvement through rigorous optimization.
\end{itemize}

% -------------------------------------------------------------------------------------------------

\section{Conclusion and Future Work}
\label{sec:conclusion}

\subsection{Summary}
\label{subsec:summary}
This project successfully established a robust, reproducible pipeline for forecasting the 1-day-ahead Realized Volatility of the S&P 500 Index. The primary contribution is the empirical confirmation that, while the GARCH(1,1) model remains a strong baseline, the non-linear Machine Learning models—specifically the Random Forest Regressor—provide the most accurate out-of-sample forecasts. This predictive edge, enabled by rich feature engineering, positions ML as a superior tool for quantitative volatility prediction.

\subsection{Future Directions}
\label{subsec:future-directions}
Suggest potential improvements or extensions:
\begin{itemize}
    \item \textbf{Methodological Improvements:} Implement deep learning models, such as LSTMs or Temporal Convolutional Networks (TCNs), which may be better suited to capture long-term dependencies in the time series.
    \item \textbf{Additional Experiments:} Extend the feature engineering to include macroeconomic variables (interest rates, CPI) or technical indicators (RSI, MACD) that could further enrich the information available to the ML models.
    \item \textbf{Real-world Applications:} Apply the best-performing model (Random Forest) to practical financial applications, such as dynamic risk budgeting for a portfolio or the dynamic hedging of option positions.
\end{itemize}

% ================== REFERENCES ==================
\newpage
\section*{References}
\addcontentsline{toc}{section}{References}

% If using biblatex (recommended)
% \printbibliography[heading=none]

% Or manually:
\begin{enumerate}
    \item Author, A. (2024). \textit{Title of Article}. Journal Name, 10(2), 123-145.
    \item Smith, B. \& Jones, C. (2023). \textit{Book Title}. Publisher.
    \item Dataset Source. (2024). Dataset Name. Available at: \url{https://example.com}
\end{enumerate}

% ================== APPENDICES ==================
\newpage
\appendix
\section{Additional Figures}
\label{app:figures}

Include supplementary figures or tables that support but aren't essential to the main narrative.

\section{Code Repository}
\label{app:code}

\noindent
\textbf{GitHub Repository:} \url{https://github.com/yourusername/project-repo}

\noindent
Provide information about:
\begin{itemize}